---
title: "Mehtre_Term_Project"
author: "Vijaykumar Mehtre"
date: "`r Sys.Date()`"
output: pdf_document
---
# Introduction

## Problem Statement :

## Reducing marketing resources by identifying customers who would subscribe to term deposit and thereby direct marketing efforts to them.

Bank marketing is known for its nature of developing a unique brand image, which is treated as the capital reputation of the financial academy. It is very important for a bank to develop good relationship with valued customers accompanied by innovative ideas which can be used as measures to meet their requirements.

Customers expect quality services and returns. There are good chances that the quality factor will be the sole determinant of successful banking corporations. Therefore,  banks need to acknowledge the imperative of proactive Bank Marketing and Customer Relationship Management and also take systematic steps in this direction.

### What is a Term Deposit ?
A time deposit or term deposit is a deposit in a financial institution with a specific maturity date or a period to maturity, commonly referred to as its "term". Time deposits differ from at call deposits, such as savings or checking accounts, which can be withdrawn at any time, without any notice or penalty. Deposits that require notice of withdrawal to be given are effectively time deposits, though they do not have a fixed maturity date.

A term deposit is a fixed-term investment that includes the deposit of money into an account at a financial institution. Term deposit investments usually carry short-term maturities ranging from one month to a few years and will have varying levels of required minimum deposits.

The investor must understand when buying a term deposit that they can withdraw their funds only after the term ends. In some cases, the account holder may allow the investor early termination or withdrawal if they give several days notification. Also, there will be a penalty assessed for early termination.

# Research questions
1. What is the relationship between marital status and the likelihood of subscribing to a term deposit?

2. How does the type of job held by a customer impact their decision to subscribe to a term deposit?

3. Are customers with a previous default more or less likely to subscribe to a term deposit, and how does this impact marketing strategies?

4. What is the effect of the number of times a customer was previously contacted (previous) on their likelihood to subscribe to a term deposit, and how should this influence future marketing efforts?

5. How does the duration of the marketing campaign (duration) affect the subscription rate, and can this be used to optimize future campaign strategies?

6. What are the most effective communication channels (contact) for encouraging term deposit subscriptions, and how can this knowledge inform marketing resource allocation?

# Approach
To address the problem statement of reducing marketing resources by identifying customers likely to subscribe to a term deposit in R, you can follow these general steps:

1. Data Import and Preprocessing:
   - Load the dataset into R using functions like `read.csv` or any relevant data import functions.
   - Preprocess the data, which may include handling missing values, data type conversions, and data cleaning.

2. Exploratory Data Analysis (EDA):
   - Conduct EDA to understand the dataset. Use summary statistics, visualizations (e.g., histograms, box plots, or scatter plots), and correlation analysis to gain insights into the data.

3. Feature Engineering:
   - Create new features or modify existing ones if needed. For example, you might want to convert categorical variables into numerical format using techniques like one-hot encoding.

4. Data Splitting:
   - Split the data into training and testing sets. The training set will be used to build predictive models, and the testing set will be used to evaluate their performance.

5. Model Building:
   - Choose an appropriate predictive modeling technique, such as logistic regression, decision trees, random forests, or gradient boosting.
   - Train the model using the training data.

6. Model Evaluation:
   - Assess the model's performance on the testing data using evaluation metrics like accuracy, precision, recall, F1-score, and ROC-AUC, depending on the nature of the problem (classification).

7. Feature Importance Analysis:
   - Determine the importance of each feature in predicting term deposit subscriptions. This can help identify which customer attributes are most influential.

8. Customer Segmentation:
   - Use clustering techniques like K-means or hierarchical clustering to segment customers based on their characteristics or behavior.

9. Resource Allocation:
   - Develop a strategy for allocating marketing resources based on the segmentation and predictive model results. For example, allocate more resources to segments with a higher likelihood of subscribing.

10. Ethical Considerations:
    - Consider ethical implications, especially with regards to data privacy and fairness when targeting customers.

11. Optimization:
    - Continuously monitor and optimize the marketing strategy based on the results and feedback. This may involve A/B testing and fine-tuning marketing efforts.

12. Reporting and Visualization:
    - Present your findings and strategies in a clear and concise manner using RMarkdown or other reporting tools. Visualizations, tables, and graphs can be helpful for conveying the results.

# Discuss how your proposed approach will address (fully or partially) this problem.
The proposed approach outlined earlier aims to address the problem of reducing marketing resources by identifying customers likely to subscribe to a term deposit through a systematic and data-driven process. Here's how each step in the approach helps to tackle this problem:

1. **Data Import and Preprocessing:**
   - This step ensures that the data is ready for analysis by handling missing values, converting data types, and cleaning the dataset. Clean data is essential for accurate modeling and decision-making.

2. **Exploratory Data Analysis (EDA):**
   - EDA helps in understanding the dataset, including the distribution of variables and potential patterns. This understanding can guide subsequent modeling and segmentation efforts.

3. **Feature Engineering:**
   - Creating or modifying features allows you to capture the most relevant information from the dataset, improving the model's ability to identify potential term deposit subscribers.

4. **Data Splitting:**
   - By splitting the data into training and testing sets, the approach ensures that the predictive models are evaluated on unseen data, providing a realistic estimate of their performance.

5. **Model Building:**
   - Building predictive models, such as logistic regression or decision trees, allows for the quantification of the relationship between customer attributes and the likelihood of subscribing to a term deposit.

6. **Model Evaluation:**
   - Model evaluation metrics (e.g., accuracy, precision, recall, F1-score) provide a quantitative measure of the model's performance, indicating its ability to predict term deposit subscriptions accurately.

7. **Feature Importance Analysis:**
   - Understanding the importance of each feature helps in identifying which customer attributes have the most influence on subscription decisions. This information is valuable for focusing marketing efforts.

8. **Customer Segmentation:**
   - Clustering customers into segments based on their characteristics or behavior enables more targeted marketing. Customers with similar traits can be addressed with specific marketing strategies.

9. **Resource Allocation:**
   - Using the insights from customer segmentation and predictive modeling, the approach guides resource allocation. More resources can be allocated to customer segments with a higher likelihood of subscription, optimizing marketing efforts.

10. **Ethical Considerations:**
    - Addressing ethical considerations ensures that marketing strategies respect data privacy and promote fairness in customer targeting, which is essential for maintaining trust and compliance with regulations.

11. **Optimization:**
    - Continuous monitoring and optimization of marketing strategies based on results and feedback allow for adaptation to changing customer behavior and market conditions, ensuring continued effectiveness.

12. **Reporting and Visualization:**
    - Communicating the findings and strategies through reporting and visualization tools ensures that the insights are accessible and actionable for marketing and management teams.

Overall, this approach leverages data analysis and modeling to identify customer segments most likely to subscribe to a term deposit, allowing marketing resources to be directed more effectively, ultimately reducing costs and improving the success rate of marketing campaigns. It combines data science techniques with business strategy to address the problem comprehensively.

# Data  (Minimum of 3 Datasets - but no requirement on number of fields or rows)

## Original source where the data was obtained is cited and, if possible, hyperlinked.

*Bank_Dataset_1*:https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset

*Bank_Dataset_2*:https://www.kaggle.com/datasets/prakharrathi25/banking-dataset-marketing-targets

*Bank_Dataset_3*:Moro,S., Rita,P., and Cortez,P.. (2012). Bank Marketing. UCI Machine Learning Repository. https://doi.org/10.24432/C5K306.

## Source data is thoroughly explained (i.e. what was the original purpose of the data, when was it collected, how many variables did the original have, explain any peculiarities of the source data such as how missing values are recorded, or how data was imputed, etc.).

**Bank_Dataset_1:**
Context
Find the best strategies to improve for the next marketing campaign. How can the financial institution have a greater effectiveness for future marketing campaigns? In order to answer this, we have to analyze the last marketing campaign the bank performed and identify the patterns that will help us find conclusions in order to develop future strategies.

Source
[Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014

This is the classic marketing bank dataset uploaded originally in the UCI Machine Learning Repository. The dataset gives you information about a marketing campaign of a financial institution in which you will have to analyze in order to find ways to look for future strategies in order to improve future marketing campaigns for the bank.


There are 17 Columns , having 7 Integer , 6 String and 4 Boolean.

#   Column     Non-Null Count  Dtype 
---  ------     --------------  ----- 
 0   age        11162 non-null  int64 
 1   job        11162 non-null  object
 2   marital    11162 non-null  object
 3   education  11162 non-null  object
 4   default    11162 non-null  object
 5   balance    11162 non-null  int64 
 6   housing    11162 non-null  object
 7   loan       11162 non-null  object
 8   contact    11162 non-null  object
 9   day        11162 non-null  int64 
 10  month      11162 non-null  object
 11  duration   11162 non-null  int64 
 12  campaign   11162 non-null  int64 
 13  pdays      11162 non-null  int64 
 14  previous   11162 non-null  int64 
 15  poutcome   11162 non-null  object
 16  deposit    11162 non-null  object
 

```{r read-data-file-dataset1}
# Specify the file path to your CSV file with forward slashes
DS_1_file_path <- "C:/Users/VJ/Desktop/Bruin/DSC 520/Project/bank_dataset_1.csv"

# Use read.csv() to import the CSV file into a data frame
Data_File_1 <- read.csv(DS_1_file_path)
head(Data_File_1)
summary(Data_File_1)
```
```{r Checking-missing-values-df1}
missing_values <- sum(is.na(Data_File_1))
print(missing_values)
```
**Bank_Dataset_2:**

Term deposits are a major source of income for a bank. A term deposit is a cash investment held at a financial institution. Your money is invested for an agreed rate of interest over a fixed amount of time, or term. The bank has various outreach plans to sell term deposits to their customers such as email marketing, advertisements, telephonic marketing, and digital marketing.

Telephonic marketing campaigns still remain one of the most effective way to reach out to people. However, they require huge investment as large call centers are hired to actually execute these campaigns. Hence, it is crucial to identify the customers most likely to convert beforehand so that they can be specifically targeted via call.

The data is related to direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe to a term deposit (variable y).

Content
The data is related to the direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed by the customer or not. The data folder contains two datasets:-

45,211 rows and 18 columns ordered by date (from May 2008 to November 2010)

Detailed Column Descriptions
bank client data:

1 - age (numeric)
2 - job : type of job (categorical: "admin.","unknown","unemployed","management","housemaid","entrepreneur","student",
"blue-collar","self-employed","retired","technician","services")
3 - marital : marital status (categorical: "married","divorced","single"; note: "divorced" means divorced or widowed)
4 - education (categorical: "unknown","secondary","primary","tertiary")
5 - default: has credit in default? (binary: "yes","no")
6 - balance: average yearly balance, in euros (numeric)
7 - housing: has housing loan? (binary: "yes","no")
8 - loan: has personal loan? (binary: "yes","no")
# related with the last contact of the current campaign:
9 - contact: contact communication type (categorical: "unknown","telephone","cellular")
10 - day: last contact day of the month (numeric)
11 - month: last contact month of year (categorical: "jan", "feb", "mar", …, "nov", "dec")
12 - duration: last contact duration, in seconds (numeric)
# other attributes:
13 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
14 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)
15 - previous: number of contacts performed before this campaign and for this client (numeric)
16 - poutcome: outcome of the previous marketing campaign (categorical: "unknown","other","failure","success")

Output variable (desired target):
17 - y - has the client subscribed a term deposit? (binary: "yes","no")

Missing Attribute Values: None

Citation
This dataset is publicly available for research. It has been picked up from the UCI Machine Learning with random sampling and a few additional columns.

Please add this citation if you use this dataset for any further analysis.

S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014

```{r read-data-file-dataset2}
# Specify the file path to your CSV file with forward slashes
DS_2_file_path <- "C:/Users/VJ/Desktop/Bruin/DSC 520/Project/bank_dataset_2.csv"

# Use read.csv() to import the CSV file into a data frame
Data_File_2 <- read.csv(DS_2_file_path)
head(Data_File_2)
summary(Data_File_2)
```
```{r Checking-missing-values-df2}
missing_values <- sum(is.na(Data_File_2))
print(missing_values)
```
**Bank_Dataset_3:**

Abstract:
The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).

Data Set Information:

The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed.

Attribute Information:

Bank client data:

Age (numeric)
Job : type of job (categorical: 'admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown')
Marital : marital status (categorical: 'divorced', 'married', 'single', 'unknown' ; note: 'divorced' means divorced or widowed)
Education (categorical: 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate','professional.course','university.degree', 'unknown')
Default: has credit in default? (categorical: 'no', 'yes', 'unknown')
Housing: has housing loan? (categorical: 'no', 'yes', 'unknown')
Loan: has personal loan? (categorical: 'no', 'yes', 'unknown')
Related with the last contact of the current campaign:
Contact: contact communication type (categorical:'cellular','telephone')
Month: last contact month of year (categorical: 'jan', 'feb', 'mar',…, 'nov', 'dec')
Day_of_week: last contact day of the week (categorical:'mon','tue','wed','thu','fri')
Duration: last contact duration, in seconds (numeric). Importantnote: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known.Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.

Other attributes:

Campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)
Pdays: number of days that passed by after the client was last
contacted from a previous campaign (numeric; 999 means client was not previously contacted)
Previous: number of contacts performed before this campaign and for this client (numeric)
Poutcome: outcome of the previous marketing campaign (categorical:'failure','nonexistent','success')

```{r read-data-file-dataset3}
# Specify the file path to your CSV file with forward slashes
DS_3_file_path <- "C:/Users/VJ/Desktop/Bruin/DSC 520/Project/bank-additional-full_dataset3.csv"

# Use read.csv() to import the CSV file into a data frame
Data_File_3 <- read.csv(DS_3_file_path)
head(Data_File_3)
summary(Data_File_3)
```
```{r Checking-missing-values-df3}
missing_values <- sum(is.na(Data_File_3))
print(missing_values)
```

# Required Packages
R offers a wide range of packages and libraries for each of these steps. For example, `tidyverse` or ggplot2,dplyr can be useful for data manipulation and visualization, while `caret` and `randomForest` are popular for modeling. The choice of specific packages and functions will depend on your data and research needs.


# Plots and Table Needs
We are going to use different Charts .
Bar Charts:

Use bar charts to visualize categorical data, such as the distribution of term deposit subscriptions by marital status, education level, job type, etc.
Grouped bar charts can be used to compare the subscription rates between different categories.

Histograms and Density Plots:

Use histograms and density plots to show the distribution of continuous variables like age, balance, and campaign duration.
These plots help you understand the spread and central tendencies of the data.
Pie Charts:

Pie charts can be used to show the distribution of categorical variables, such as the proportion of different education levels or housing loan statuses.

Scatter Plots:

Scatter plots are useful for visualizing the relationship between two continuous variables. For example, you can use them to explore the relationship between balance and campaign duration.

Tables:

Tables can present summary statistics, including means, medians, standard deviations, and other relevant metrics for key variables.
Cross-tabulation tables can be used to display the relationship between two categorical variables, showing counts and percentages.

# Project Step 2

## How to import and clean my data
```{r Import_dataset1}
# Specify the file path to your CSV file with forward slashes
DS_1_file_path <- "C:/Users/VJ/Desktop/Bruin/DSC 520/Project/bank_dataset_1.csv"

# Use read.csv() to import the CSV file into a data frame
Data_File_1 <- read.csv(DS_1_file_path)

```
## What does the final data set look like?
```{r Data_Explorer}
head(Data_File_1)
summary(Data_File_1)
str(Data_File_1)

```

```{r missing_values}
# Handle missing values
Bank_Dataset1 <- is.na(Data_File_1)
```
There is no Missing data in the given Dataset
```{r remove_duplicate}
Bank_Dataset1 <- unique(Data_File_1)
```
All the recods are unquie in the dataset

## Questions for future steps.
1. Right now don't know the outliers and relationship between Variables

## What information is not self-evident?

1. Understand the Data:

Begin by thoroughly understanding the dataset, its structure, and the context in which it was collected. This involves examining data documentation and metadata, if available.

2.Data Visualization:

Visualize the data using various plots and charts, such as histograms, box plots, scatter plots, bar charts, and heatmaps. Visualization can reveal patterns, trends, and potential outliers that may not be immediately obvious from the raw data.

3.Summary Statistics:

Calculate and analyze summary statistics like mean, median, standard deviation, variance, skewness, and kurtosis. These statistics can provide insights into the central tendency, spread, and shape of data distributions.

4.Correlation Analysis:

Explore correlations between variables to identify relationships and dependencies. Correlation matrices and scatter plots can reveal connections between variables, which may suggest causal relationships.

5.Hypothesis Testing:

Formulate hypotheses about the data and use statistical tests to test these hypotheses. Common tests include t-tests, chi-squared tests, and analysis of variance (ANOVA). The results of hypothesis tests can reveal significant differences or associations in the data.

## What are different ways you could look at this data?

We can employ various data analysis and machine learning techniques. Here are different approaches and methods you could use to answer this question:

*1.Descriptive Statistics and Data Visualization:*

Start with basic statistics and data visualization to understand the characteristics of customers who have subscribed to term deposits. Compare them to those who haven't.
Use bar charts, pie charts, and histograms to visualize demographic information, such as age, education, and marital status, for both groups.
Explore the distribution of numeric variables like balance and duration for subscribers and non-subscribers.
]
*2.Feature Importance Analysis:*

Use feature importance techniques to identify which customer attributes have the most influence on subscription decisions.
Techniques such as tree-based models (e.g., Random Forest) or statistical methods like chi-squared tests can help determine the most significant features.

*3.Predictive Modeling:*

Build predictive models to estimate the likelihood of a customer subscribing to a term deposit.
Utilize classification algorithms like Logistic Regression, Decision Trees, Random Forest, or Gradient Boosting.
Use a dataset split into training and testing sets to evaluate model performance.
Assess model accuracy, precision, recall, F1-score, and ROC-AUC to understand the model's predictive power.

*4.Segmentation Analysis:*

Segment the customer base into groups with similar characteristics or behaviors.
Cluster analysis or customer segmentation techniques can help identify distinct customer segments.
Analyze the subscription rates within each segment and focus marketing efforts on high-potential segments.

*5.Customer Behavior Analysis:*

Analyze historical customer behavior and interactions with the bank.
Explore how past behavior, such as the number of previous campaigns, affects the likelihood of subscribing to a term deposit.
Utilize sequence analysis or association rule mining to find patterns in customer interactions.

*6.Time Series Analysis:*

If the data includes a time dimension, perform time series analysis to uncover trends in subscription rates over time.
Identify seasonality and temporal patterns that may impact marketing efforts.

## How do you plan to slice and dice the data?

I am planing to slice the data based on predication variable i.e Deposit Variable = TRUE . So that i can see by historically who has subscribe for term deposit and then decide which variable is contributing most in customer positive decision.

Also , age is the big factor in the data and i am going to slice it by age as well to see which age group customers are likely has more term deposits . 


## How could you summarize your data to answer key questions?

*1.Frequency Distributions:*

Create frequency distributions to summarize the number of occurrences of each category or value within a variable.
This is particularly useful for understanding the distribution of categorical data.

*2.Grouping and Aggregation:*

Group data by specific attributes or categories and calculate aggregate statistics for each group.
This is helpful for comparing subsets of data and identifying patterns or differences.

*3.Explore the Correlation between numerical features*

*4.Find Pair Plot*

*5.Check the Data set is balanced or not based on target values in classification*

## What types of plots and tables will help you to illustrate the findings to your questions?

1. Heatmap  - Mostly going to use to see the correlation
2. Box Plot - going to use for Outlier detection
3. Bar and Line - Distribution of Variable

## What do you not know how to do right now that you need to learn to answer your questions?

I am not sure which Linear/Logistical = Model i am going to use for my data analysis

##Do you plan on incorporating any machine learning techniques to answer your research questions? Explain.

As of  now i have not think about it but i will research it more and try to apply machine learning techniques as well if required.


# STEP 3

# Introduction

## Problem Statement :

## Reducing marketing resources by identifying customers who would subscribe to term deposit and thereby direct marketing efforts to them.

Bank marketing is known for its nature of developing a unique brand image, which is treated as the capital reputation of the financial academy. It is very important for a bank to develop good relationship with valued customers accompanied by innovative ideas which can be used as measures to meet their requirements.

Customers expect quality services and returns. There are good chances that the quality factor will be the sole determinant of successful banking corporations. Therefore,  banks need to acknowledge the imperative of proactive Bank Marketing and Customer Relationship Management and also take systematic steps in this direction.


# Discuss how your proposed approach will address (fully or partially) this problem.
The proposed approach outlined earlier aims to address the problem of reducing marketing resources by identifying customers likely to subscribe to a term deposit through a systematic and data-driven process. Here's how each step in the approach helps to tackle this problem:

1. **Data Import and Preprocessing:**
   - This step ensures that the data is ready for analysis by handling missing values, converting data types, and cleaning the dataset. Clean data is essential for accurate modeling and decision-making.

2. **Exploratory Data Analysis (EDA):**
   - EDA helps in understanding the dataset, including the distribution of variables and potential patterns. This understanding can guide subsequent modeling and segmentation efforts.

3. **Feature Engineering:**
   - Creating or modifying features allows you to capture the most relevant information from the dataset, improving the model's ability to identify potential term deposit subscribers.

4. **Data Splitting:**
   - By splitting the data into training and testing sets, the approach ensures that the predictive models are evaluated on unseen data, providing a realistic estimate of their performance.

5. **Model Building:**
   - Building predictive models, such as logistic regression or decision trees, allows for the quantification of the relationship between customer attributes and the likelihood of subscribing to a term deposit.

6. **Model Evaluation:**
   - Model evaluation metrics (e.g., accuracy, precision, recall, F1-score) provide a quantitative measure of the model's performance, indicating its ability to predict term deposit subscriptions accurately.

7. **Feature Importance Analysis:**
   - Understanding the importance of each feature helps in identifying which customer attributes have the most influence on subscription decisions. This information is valuable for focusing marketing efforts.

8. **Customer Segmentation:**
   - Clustering customers into segments based on their characteristics or behavior enables more targeted marketing. Customers with similar traits can be addressed with specific marketing strategies.

9. **Resource Allocation:**
   - Using the insights from customer segmentation and predictive modeling, the approach guides resource allocation. More resources can be allocated to customer segments with a higher likelihood of subscription, optimizing marketing efforts.

10. **Ethical Considerations:**
    - Addressing ethical considerations ensures that marketing strategies respect data privacy and promote fairness in customer targeting, which is essential for maintaining trust and compliance with regulations.

11. **Optimization:**
    - Continuous monitoring and optimization of marketing strategies based on results and feedback allow for adaptation to changing customer behavior and market conditions, ensuring continued effectiveness.

12. **Reporting and Visualization:**
    - Communicating the findings and strategies through reporting and visualization tools ensures that the insights are accessible and actionable for marketing and management teams.

Overall, this approach leverages data analysis and modeling to identify customer segments most likely to subscribe to a term deposit, allowing marketing resources to be directed more effectively, ultimately reducing costs and improving the success rate of marketing campaigns. It combines data science techniques with business strategy to address the problem comprehensively.

# Analysis

### Loading Packges
```{r}
library(gmodels)

```


```{r Import_dataset_Final}
# Specify the file path to your CSV file with forward slashes
DS_1_file_path <- "C:/Users/VJ/Desktop/Bruin/DSC 520/Project/bank-additional-full_dataset3.csv"

# Use read.csv() to import the CSV file into a data frame
Data_File_1 <- read.csv(DS_1_file_path,sep = ";",
                     stringsAsFactors = F)
```
```{r}
dim(Data_File_1)
```
The dataset has 41,188 rows and 21 columns.


```{r}
names(Data_File_1)
```
The first 20 variables are our potential explanatory variables and the last one ("y") is the dependent variable.



```{r Data Analysis}
head(Data_File_1)
summary(Data_File_1)
str(Data_File_1)

```

```{r missing_values_analysis}
# Handle missing values
Bank_Dataset1 <- is.na(Data_File_1)
```
There is no Missing data in the given Dataset
```{r check_duplicate}
Bank_Dataset1 <- unique(Data_File_1)
```
```{r remove_unknown}
# Removing unknown values
Bank_Dataset1 <- na.omit(Bank_Dataset1)
table(Bank_Dataset1$y)
```
```{r}
CrossTable(Bank_Dataset1$y)
```
This is an unbalanced two-levels categorical variable, 88.7% of values taken are "no" (or "0") and only 11.3% of the values are "yes" (or "1"). It is more natural to work with a 0/1 dependent variable.

```{r}
Bank_Dataset1 = Bank_Dataset1 %>% 
#If y is equal to "yes", it is replaced with "1", otherwise with "0". The resulting values are then converted to a factor with levels "0" and "1"
  mutate(y_binary = ifelse(y == "no",0,1))
```

```{r}
head(Bank_Dataset1)
```
```{r}
sum(Bank_Dataset1 == "unknown")
```
There are 12,718 unknown values in the dataset, let's try to find out which variables suffer the most from those "missing values".
```{r}
Bank_Dataset1 %>% 
  summarise_all(list(~sum(. == "unknown"))) %>% 
  gather(key = "variable", value = "nr_unknown") %>% 
  arrange(-nr_unknown)
```
6 features have at least 1 unknown value. Before deciding how to manage those missing values, we'll study each variable and take a decision after visualisations. We can't afford to delete 8,597 rows in our dataset, it's more than 20% of our observations.

```{r theme}
## default theme for ggplot
theme_set(theme_bw())

## setting default parameters for mosaic plots
mosaic_theme = theme(axis.text.x = element_text(angle = 90,
                                                hjust = 1,
                                                vjust = 0.5),
                     axis.text.y = element_blank(),
                     axis.ticks.y = element_blank())
```



#### Age

What kind of persons were contacted during this marketing campaign?
```{r}
summary(Bank_Dataset1$age)
```
Ages range from 17 to 98, there doesn't seem anything strange from there. The other summary statistics are fine, the average is 40 years old.
```{r}
Bank_Dataset1 %>% 
  ggplot() +
  aes(x = age) +
  geom_bar() +
  geom_vline(xintercept = c(30, 60), 
             col = "red",
             linetype = "dashed") +
  facet_grid(y_binary ~ .,
             scales = "free_y") +
  scale_x_continuous(breaks = seq(0, 100, 5))

```
First of all, It seems that the banks are not very much interested by contacting the older population.
Even though, after the 60-years threshold, the relative frequency is higher when y = 1.
In other words, we can say that elderly persons are more likely to subscribe to a term deposit.

We’re replacing the continious variable “age” by this categorical variable.
We might lose some information from this continious-to-discrete transformation, but there wasn’t any clear pattern between years.
Cutting into classes will make the algorithms easier to interpret later.

```{r}
Bank_Dataset1 = Bank_Dataset1 %>% 
  mutate(age_discrete = if_else(age > 60, "high", if_else(age > 30, "mid", "low")))
```

Cross-tab with our dependent variable
```{r age crosstab}

CrossTable(Bank_Dataset1$age_discrete, Bank_Dataset1$y_binary)
```
45.5% of people over 60 years old subscribed to a term deposit,
which is a lot in comparison with younger individuals (15.2% for young adults (aged lower than 30)
and only 9.4% for the remaining observations said yes (aged between 30 and 60)).

#### Jobs

What are the types of jobs represented in our data?

```{r}
table(Bank_Dataset1$job)

```
We have 330 unknown jobs.

```{r}
Bank_Dataset1 = Bank_Dataset1 %>% 
  filter(job != "unknown")
```

Cross-tab with our dependent variable
```{r crosstab-job}
CrossTable(Bank_Dataset1$job, Bank_Dataset1$y_binary)

```

```{r job-cross-table}
library(ggplot2)
library(vcd)

Bank_Dataset1 %>%
  ggplot() +
  geom_mosaic(aes(x = product(y_binary, job), fill = y), width = 0.7, position = "dodge") +
  theme_minimal()

```

Higher response among students (31.4%) and retired people (25.2%).

Other classes range between 6.9% (blue-collar) and 14.2 (unemployed).

We also see that we can ignore "unknown". No big effect seen here.

#### Marital status

How is marital status effecting client behavior?

```{r marital-status}

table(Bank_Dataset1$marital)

```
71 Unknows are there


```{r}
Bank_Dataset1 = Bank_Dataset1 %>% 
  filter(marital != "unknown")
```

Cross-tab with our dependent variable:

```{r maritial crosstab}

CrossTable(Bank_Dataset1$marital, Bank_Dataset1$y)

library(ggplot2)
library(vcd)

Bank_Dataset1 %>%
  ggplot() +
  geom_mosaic(aes(x = product(y_binary, marital), fill = y), width = 0.7, position = "dodge") +
  theme_minimal()
```
No big effect of marriage. Singles (14.0%) slightly more like to say "yes" than divorced (10.3%) or married customers (10.2%).

```{r}
marriage_table <- table(Bank_Dataset1$marital, Bank_Dataset1$y)
marriage_tab <- as.data.frame(prop.table(marriage_table, 2))
colnames(marriage_tab) <-  c("marital", "y", "perc")

ggplot(data = marriage_tab, aes(x = marital, y = perc, fill = y)) + 
  geom_bar(stat = 'identity', position = 'dodge', alpha = 2/3) + 
  xlab("Marital")+
  ylab("Percent")

```

#### Education

How educated are the clients and how are that effecting their choice?

```{r education}

table(Bank_Dataset1$education)
```
1595 unknowns here.

Cross-tab with our dependent variable:

```{r education crosstab}

CrossTable(Bank_Dataset1$education, Bank_Dataset1$y)

library(ggplot2)
library(vcd)

Bank_Dataset1 %>%
  ggplot() +
  geom_mosaic(aes(x = product(y_binary, education), fill = y), width = 0.7, position = "dodge") +
  theme_minimal()
```
It appears that a positive correlation exists between the number of years of education and the odds of subscribing to a term deposit.
Among the 1595 rows containing the “unknown” value, 234 of them subscribed to a term deposit. This is around 5% of the total group of subscribers.

Since we’re facing a very unbalanced dependent variable situation, we can not afford to discard those rows. This category has the highest relative frequency of “y = 1” (14.7%)

It might make sense to recode these as "university.degree holders" as they are the most similar (13.7%).


#### Default

How many of our clients are in default?

```{r default}

table(bank_data$default)
```
8597 unknowns in default.

Cross-tab with our dependent variable:

```{r default crosstab}

CrossTable(Bank_Dataset1$default, Bank_Dataset1$y)

library(ggplot2)
library(vcd)

Bank_Dataset1 %>%
  ggplot() +
  geom_mosaic(aes(x = product(y_binary, default), fill = y), width = 0.7, position = "dodge") +
  theme_minimal()
```
Only 3 individuals replied “yes” to the question “Do you have credit in default?”.
People either answered “no” (79.3%) or didn't even reply (20.7%), which gives us zero information.


I decide to not use this variable in the final models.
```{r}
Bank_Dataset1 = Bank_Dataset1 %>% 
  select(-default)
```

#### Housing

Does clients have a housing loan?

```{r housing-loan}

table(Bank_Dataset1$housing)
```
984 uknowns about housing 

Cross-tab with our dependent variable:


```{r default crosstab}

CrossTable(Bank_Dataset1$housing, Bank_Dataset1$y)

library(ggplot2)
library(vcd)

Bank_Dataset1 %>%
  ggplot() +
  geom_mosaic(aes(x = product(y_binary, housing), fill = y), width = 0.7, position = "dodge") +
  theme_minimal()
```
Not much observable variation between those who have housing loans (11.6%) and those who do not(10.6%).Unknown at 10.8%

Checking this mathematically with a Chi-Squared Test:
```{r housing chi}

chisq.test(Bank_Dataset1$housing, Bank_Dataset1$y)
```
The p-value associated to the Chi-squared test equals to 0.065, which is higher than a 0.05-threshold. So, for a confidence level of 95%, there's no association between the dependent variable y and our feature housing. We're removing it from the dataset.

```{r}
Bank_Dataset1 = Bank_Dataset1 %>% 
  select(-housing)
```

#### Personal Loan

Do clients have a personal loan already? How does that effect thier take-up?

```{r personal-loan}
table(Bank_Dataset1$loan)
```
984 unknowns


Cross-tab with our dependent variable:


```{r loan crosstab}

CrossTable(Bank_Dataset1$loan, Bank_Dataset1$y)

library(ggplot2)
library(vcd)

Bank_Dataset1 %>%
  ggplot() +
  geom_mosaic(aes(x = product(y_binary, loan), fill = y), width = 0.7, position = "dodge") +
  theme_minimal()
```
Not much variation between 11.3% (for no) and 10.9% (for yes).

Checking this mathematically with a Chi-Squared Test:

```{r loan chi}
chisq.test(Bank_Dataset1$loan, Bank_Dataset1$y)

```
The p-value associated to the Chi-squared test equals to 0.648, which is higher than a 0.01-threshold. So, for a confidence level of 99%, there's no association between the dependent variable y and our feature loan. We're also removing it from the dataset.

```{r}
Bank_Dataset1 = Bank_Dataset1 %>% 
  select(-loan)
```
#### Contact

How were clients contacted and does it make a difference?

```{r contact}

table(Bank_Dataset1$contact)
```

```{r loan crosstab}

CrossTable(Bank_Dataset1$contact, Bank_Dataset1$y)

library(ggplot2)
library(vcd)

Bank_Dataset1 %>%
  ggplot() +
  geom_mosaic(aes(x = product(y_binary, contact), fill = y), width = 0.7, position = "dodge") +
  theme_minimal()
```
This feature is really interesting, 14.7% of cellular responders subscribed to a term deposit while only 5.2% of telephone responders did.

#### Month

Does month make a difference?
```{r}
month_recode = c("jan" = "(01)jan",
                 "feb" = "(02)feb",
                 "mar" = "(03)mar",
                 "apr" = "(04)apr",
                 "may" = "(05)may",
                 "jun" = "(06)jun",
                 "jul" = "(07)jul",
                 "aug" = "(08)aug",
                 "sep" = "(09)sep",
                 "oct" = "(10)oct",
                 "nov" = "(11)nov",
                 "dec" = "(12)dec")

Bank_Dataset1 = Bank_Dataset1 %>% 
  mutate(month = recode(month, !!!month_recode))
```
```{r month crosstab}

CrossTable(Bank_Dataset1$month, Bank_Dataset1$y)

Bank_Dataset1 %>% 
  ggplot() +
  aes(x = month, y = after_stat(count)/nrow(Bank_Dataset1), fill = y) +
  geom_bar() +
  ylab("relative frequency")

month_table <- table(Bank_Dataset1$month, Bank_Dataset1$y)
month_tab <- as.data.frame(prop.table(month_table, 2))
colnames(month_tab) <-  c("month", "y", "perc")

ggplot(data = month_tab, aes(x = month, y = perc, fill = y)) + 
  geom_bar(stat = 'identity', position = 'dodge', alpha = 2/3) + 
  xlab("Month")+
  ylab("Percent")

```
First of all, we can notice that no contact has been made during January and February. The highest spike occurs during May, with 33.4% of total contacts, but it has the worst ratio of subscribers over persons contacted (6.5%). Every month with a very low frequency of contact (march, september, october and december) shows very good results (between 44% and 51% of subscribers). December aside, there are enough observations to conclude this isn't pure luck, so this feature will probably be very important in models.

#### Day of the week

Does the day of the week matter?

Cross-tab with our dependent variable:

```{r week crosstab}

CrossTable(Bank_Dataset1$day_of_week, Bank_Dataset1$y)

Bank_Dataset1 %>% 
  ggplot() +
  aes(x = day_of_week, y = after_stat(count)/nrow(Bank_Dataset1), fill = y) +
  geom_bar() +
  ylab("relative frequency")
```
Calls aren't made during weekend days. If calls are evenly distributed between the different week days, Thursdays tend to show better results (12.1% of subscribers among calls made this day) unlike Mondays with only 10.0% of successful calls. However, those differences are small, which makes this feature not that important. It would've been interesting to see the attitude of responders from weekend calls.

#### Campaign

How many times was the client contacted during this campaign?

```{r campaign}

Bank_Dataset1 %>% 
  ggplot() +
  aes(x = campaign) +
  geom_bar() +
  facet_grid(y ~ .,
             scales = "free_y") +
  scale_x_continuous(breaks = seq(0, 50, 5))
```
Calling more than ten times a same person during a single marketing campaign seems excessive. We'll consider those as outliers, even if marketing harrassment a real thing. However, we can see that on the chart that harassment isn't working at all.

```{r}
Bank_Dataset1 = Bank_Dataset1 %>% 
  filter(campaign <= 10)

Bank_Dataset1 %>% 
  ggplot() +
  aes(x = campaign) +
  geom_bar() +
  facet_grid(y ~ .,
             scales = "free_y") +
  scale_x_continuous(breaks = seq(0, 10, 1))
```
Filtered Cross-tab with our dependent variable:

```{r campaign crosstab}

CrossTable(Bank_Dataset1$campaign, Bank_Dataset1$y)

Bank_Dataset1 %>%
  ggplot() +
  geom_mosaic(aes(x = product(y_binary, campaign), fill = y), width = 0.7) +
  theme_minimal()
```
There is a linear pattern observable that depends on the different values of Campaign.
#### Pdays

If the client has already been contacted in a previous campaign, how many days passed meanwhile?

```{r}
table(Bank_Dataset1$pdays)
```
This is the number of days that passed by after the client was last contacted from a previous campaign. 999 value means the client wasn't previously contacted. Let's make a dummy out of it.


Clients who haven't been contacted in a previous campaign will be labeled "0" in the pdays_dummy variable
```{r}
Bank_Dataset1 = Bank_Dataset1 %>% 
  mutate(pdays_dummy = if_else(pdays == 999, "0", "1")) %>% 
  select(-pdays)
```
Filtered Cross-tab with our dependent variable:

```{r campaign crosstab}

CrossTable(Bank_Dataset1$pdays_dummy, Bank_Dataset1$y)

Bank_Dataset1 %>%
  ggplot() +
  geom_mosaic(aes(x = product(y_binary, pdays_dummy), fill = y), width = 0.7) +
  theme_minimal()
```
Recontacting a client after a previous campaign seems to highly increase the odds of subscription.

